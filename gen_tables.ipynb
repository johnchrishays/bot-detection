{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99af18c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-13T23:16:15.172346Z",
     "start_time": "2022-10-13T23:16:15.169969Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from biblib import Entry\n",
    "import pybtex as pbt\n",
    "import math\n",
    "import numpy as np\n",
    "import re\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "from print_table import print_single_dataset_score_table, get_max_score, print_dataset_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfec8925",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec96f398",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-13T23:18:57.309736Z",
     "start_time": "2022-10-13T23:18:57.294506Z"
    }
   },
   "outputs": [],
   "source": [
    "path = 'bot_detection_papers.tsv'\n",
    "\n",
    "df = pd.read_csv(path, sep='\\t')\n",
    "df.fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6cd0939d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-13T23:18:57.458332Z",
     "start_time": "2022-10-13T23:18:57.450021Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_df_path = 'datasets.tsv'\n",
    "\n",
    "dataset_df = pd.read_csv(dataset_df_path, sep='\\t')\n",
    "dataset_df.fillna(\"\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dcf58bb0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-13T23:18:57.634310Z",
     "start_time": "2022-10-13T23:18:57.630206Z"
    }
   },
   "outputs": [],
   "source": [
    "scores_path = '~/work/repo/bot-detection/scores.csv'\n",
    "sdt_df = pd.read_csv(scores_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfdb940",
   "metadata": {},
   "source": [
    "## Generate bibliography methods.bib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5477a63e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-13T23:16:18.009821Z",
     "start_time": "2022-10-13T23:16:17.939263Z"
    }
   },
   "outputs": [],
   "source": [
    "bib = pbt.database.BibliographyData()\n",
    "\n",
    "def add_bib_entries(df):\n",
    "    for row in df.to_dict(orient=\"records\"):\n",
    "        #print(row)\n",
    "        if row['bibtex_id'] in bib.entries.keys():\n",
    "            continue\n",
    "        if 'analyzed?' in row:\n",
    "            if not row['analyzed?']:\n",
    "                continue\n",
    "        if not row['bibtex_id']:\n",
    "            continue\n",
    "        inputdict = {\n",
    "            'author': row['authors'],\n",
    "            'title': row['title'],\n",
    "            'year': str(int(row['year']))\n",
    "        }\n",
    "\n",
    "        if row['conference?']:\n",
    "            inputdict.update({\n",
    "                'booktitle': row['booktitle'],\n",
    "                'pages': row['pages'],\n",
    "            })\n",
    "            if row['booktitle']:\n",
    "                inputdict['booktitle'] = row['booktitle'] \n",
    "            type_ = 'inproceedings'\n",
    "        else:\n",
    "            inputdict['journal'] = row['journal']\n",
    "            if row['volume']:\n",
    "                inputdict['volume'] = str(int(row['volume']))\n",
    "            if row['number']:\n",
    "                inputdict['number'] = str(int(row['number']))\n",
    "            type_ = 'article'\n",
    "        if row['publisher']:\n",
    "            inputdict['publisher'] = row['publisher']\n",
    "        if row['doi']:\n",
    "            inputdict['doi'] = row['doi']\n",
    "        if row['pages']:\n",
    "            inputdict['pages'] = row['pages']\n",
    "        entry = pbt.database.Entry(type_=type_, fields=inputdict)\n",
    "        bib.add_entry(entry=entry, key=row['bibtex_id'])\n",
    "\n",
    "add_bib_entries(df)\n",
    "add_bib_entries(dataset_df)\n",
    "\n",
    "bib.to_file(\"methods.bib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620287bc",
   "metadata": {},
   "source": [
    "## Generate table dataset -> paper that uses it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afd6e603",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-13T23:16:21.164864Z",
     "start_time": "2022-10-13T23:16:21.158494Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_dict = {}\n",
    "\n",
    "for row in df.to_dict(orient=\"records\"):\n",
    "    datasets = row['dataset(s) used'].split(\"; \")\n",
    "    for d in datasets:\n",
    "        if d in dataset_dict:\n",
    "            dataset_dict[d].append(row['bibtex_id'])\n",
    "        else:\n",
    "            dataset_dict[d] = [row['bibtex_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85826edd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-13T23:16:21.387414Z",
     "start_time": "2022-10-13T23:16:21.382262Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "midterm-2018 & \\cite{ng2023botbuster, guo2022social, antenore2022a, ilias2021deep, dimitriadis2021social, giorgi2021characterizing, yang2020scalable, sayyadiharikandeh2020detection, muo2020malicious, barhate2020twitter} \\\\\n",
      "cresci-2015 & \\cite{pham2022bot2vec:, gonzalez2022the, dimitriadis2021social, muo2020malicious, stella2019influence, echeverria2018lobo, cresci2015fame} \\\\\n",
      "twibot-2020 & \\cite{feng2022heterogeneity-aware, alothali2022bot-mgat:, rovito2022an, feng2021botrgcn, geng2021satar, dehghan2018detecting} \\\\\n",
      "rtbust-2019 & \\cite{guo2022social, ilias2021deep, yang2020scalable, sayyadiharikandeh2020detection, mendoza2020malicious, muo2020malicious, nguyen2020bot, mazza2019rtbust} \\\\\n",
      "feedback-2019 & \\cite{guo2022social, ilias2021deep, yang2020scalable, sayyadiharikandeh2020detection} \\\\\n",
      "gilani-2017 & \\cite{guo2022social, ilias2021deep, dimitriadis2021social, yang2020scalable, gilani2020classification, sayyadiharikandeh2020detection, muo2020malicious, gilani2019a, echeverria2018lobo, gilani2017of} \\\\\n",
      "stock-2018 & \\cite{guo2022social, ilias2021deep, dimitriadis2021social, yang2020scalable, sayyadiharikandeh2020detection} \\\\\n",
      "cresci-2017 & \\cite{gonzalez2022the, thavasimani2022a, heidari2021an, ilias2021deep, ilias2021detecting, geng2021satar, dimitriadis2021social, yang2020scalable, heidari2020using, heidari2020deep, sayyadiharikandeh2020detection, muo2020malicious, stella2019influence, loyola-gonzalez2019contrast, mohammad2019bot, alhosseini2019detect, , knauth2019language-agnostic, kosmajac2019twitter, kudugunta2018deep, cresci2018social, echeverria2018lobo, ferrara2017disinformation, cresci2017the, cresci2017exploiting, cresci2016dna-inspired} \\\\\n",
      "verified-2019 & \\cite{ilias2021deep, giorgi2021characterizing, yang2020scalable, sayyadiharikandeh2020detection, muo2020malicious, barhate2020twitter} \\\\\n",
      "botwiki-2019 & \\cite{ilias2021deep, dimitriadis2021social, giorgi2021characterizing, yang2020scalable, sayyadiharikandeh2020detection, muo2020malicious, barhate2020twitter} \\\\\n",
      "political-bots-2019 & \\cite{ilias2021deep, dimitriadis2021social, yang2020scalable, sayyadiharikandeh2020detection} \\\\\n",
      "vendor-purchased-2019 & \\cite{ilias2021deep, dimitriadis2021social, yang2020scalable, sayyadiharikandeh2020detection, muo2020malicious} \\\\\n",
      "celebrity-2019 & \\cite{ilias2021deep, muo2020malicious} \\\\\n",
      "pronbots-2019 & \\cite{ilias2021deep, dimitriadis2021social, yang2020scalable, sayyadiharikandeh2020detection, muo2020malicious} \\\\\n",
      "varol-2017 & \\cite{ilias2021deep, dimitriadis2021social, yang2020scalable, sayyadiharikandeh2020detection, muo2020malicious, kosmajac2019twitter, varol2017online, ferrara2017disinformation} \\\\\n",
      "caverlee-2011 & \\cite{ilias2021detecting, dimitriadis2021social, yang2020scalable, sayyadiharikandeh2020detection, muo2020malicious, alhosseini2019detect, beskow2018bot, varol2017online, wu2017adaptive, davis2016botornot, alarifi2016twitter, lee2011a, lee2010uncovering} \\\\\n",
      "pan-2019 & \\cite{geng2021satar, wang2021detecting, luo2019deepbot} \\\\\n",
      "astroturf & \\cite{dimitriadis2021social, sayyadiharikandeh2020detection} \\\\\n",
      "italian-elections & \\cite{dimitriadis2021social} \\\\\n",
      "kaiser & \\cite{sayyadiharikandeh2020detection} \\\\\n",
      "policial-bots-2019 & \\cite{muo2020malicious} \\\\\n",
      "russian-trolls-2018 & \\cite{stella2019influence} \\\\\n",
      "cresci-2017 tweets & \\cite{wei2019twitter} \\\\\n",
      "yang-2013-traditional-spambots-1 & \\cite{alhosseini2019detect} \\\\\n",
      "gilani-2017 tweets & \\cite{garcia-silva2019an} \\\\\n",
      "random-strings-2018 & \\cite{beskow2018bot} \\\\\n",
      "journalist-attack-2017 & \\cite{beskow2018bot, echeverria2018lobo} \\\\\n",
      "starwars & \\cite{echeverria2018lobo} \\\\\n",
      "besel-2018 & \\cite{echeverria2018lobo} \\\\\n",
      "debot & \\cite{echeverria2018lobo} \\\\\n",
      "darpa-challenge-2015 & \\cite{echeverria2018lobo} \\\\\n",
      "alarifi-2016 & \\cite{alarifi2016twitter} \\\\\n",
      "yang-2013 & \\cite{yang2013empirical} \\\\\n",
      "possibly spammers used in cresci-2017 or another spam dataset & \\cite{chao2011die} \\\\\n",
      " & \\cite{} \\\\\n"
     ]
    }
   ],
   "source": [
    "for k,v in dataset_dict.items():\n",
    "    impl_papers = \", \".join(dataset_dict[k])\n",
    "\n",
    "    cite_as = '\\\\cite{' + impl_papers + '} \\\\\\\\'\n",
    "    dataset_name = k\n",
    "    print(dataset_name+ \" & \" + cite_as)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3ca18b",
   "metadata": {},
   "source": [
    "## Generate table for dataset, #people/bots, description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47a8574e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-13T23:16:22.579896Z",
     "start_time": "2022-10-13T23:16:22.574771Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_df['year'] = dataset_df['dataset name'].str[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "085cb49b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-13T23:16:23.276151Z",
     "start_time": "2022-10-13T23:16:23.264611Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_df = dataset_df.sort_values(by=['year', 'dataset name'], ascending=[False,True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "206f8a3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-13T23:16:25.330740Z",
     "start_time": "2022-10-13T23:16:25.325159Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\data{twibot-2020} & \\cite{feng2021twibot} & 3632 & 4646 \\\\\n",
      "\\data{feedback-2019} & \\cite{yang2019arming} & 380 & 139 \\\\\n",
      "\\data{pan-2019} & \\cite{rangel2015overview} & 2060 & 2060 \\\\\n",
      "\\data{rtbust-2019} & \\cite{mazza2019rtbust} & 340 & 353 \\\\\n",
      "\\data{midterm-2018} & \\cite{yang2020scalable} & 8092 & 42446 \\\\\n",
      "\\data{stock-2018} & \\cite{cresci2019fake} & 6174 & 7102 \\\\\n",
      "\\data{cresci-2017} & \\cite{cresci2017the} & 3474 & 10894 \\\\\n",
      "\\data{gilani-2017} & \\cite{gilani2017classification} & 1939 & 1492 \\\\\n",
      "\\data{cresci-2015} & \\cite{cresci2015fame} & 1957 & 3351 \\\\\n",
      "\\data{yang-2013} & \\cite{yang2013empirical} & 10000 & 1000 \\\\\n",
      "\\data{caverlee-2011} & \\cite{lee2011a} & 19276 & 22223 \\\\\n"
     ]
    }
   ],
   "source": [
    "print_dataset_table(dataset_df, benchmark_only=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6804cc37",
   "metadata": {},
   "source": [
    "## Generate table for dataset -> sdt/sota scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f30504b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-13T23:16:26.783827Z",
     "start_time": "2022-10-13T23:16:26.754615Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_names = [\n",
    "    'twibot-2020',\n",
    "    'feedback-2019',\n",
    "    'rtbust-2019',\n",
    "    'pan-2019',\n",
    "    'midterm-2018',\n",
    "    'stock-2018',\n",
    "    'cresci-2017',\n",
    "    'gilani-2017',\n",
    "    'cresci-2015',\n",
    "    'yang-2013',\n",
    "    'caverlee-2011'\n",
    "]\n",
    "\n",
    "score_dict = {}\n",
    "\n",
    "for name in dataset_names:\n",
    "    score_dict[name] = {\n",
    "        'accuracy': get_max_score(df, name, 'accuracy'),\n",
    "        'f1': get_max_score(df, name, 'f1'),\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b29a862",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-13T23:16:29.289158Z",
     "start_time": "2022-10-13T23:16:29.267855Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\data{twibot-2020} & 0.82/0.86/0.80  & 1 & \\cite{feng2022heterogeneity-aware} & -0.05/-0.03 \\\\\n",
      "\\data{feedback-2019} & 0.80/0.55/0.69  & 3 & \\cite{guo2022social} & -0.01/-0.15 \\\\\n",
      "\\data{rtbust-2019} & 0.71/0.73/0.71  & 4 & \\cite{mazza2019rtbust} & -0.22/-0.14 \\\\\n",
      "\\data{pan-2019} & 0.92/0.91/0.92  & 2 & \\cite{geng2021satar} & -0.03/-0.04 \\\\\n",
      "\\data{midterm-2018} & 0.97/0.98/0.95  & 1 & \\cite{giorgi2021characterizing} & -0.01/\\;\\;--- \\\\\n",
      "\\data{stock-2018} & 0.80/0.83/0.80  & 3 & \\;\\;---\\;\\; & \\;\\;---\\;\\;\\,/\\;\\;--- \\\\\n",
      "\\data{cresci-2017} & 0.98/0.98/0.97  & 1 & \\cite{kudugunta2018deep} & -0.02/-0.02 \\\\\n",
      "\\data{gilani-2017} & 0.77/0.72/0.76  & 3 & \\cite{gilani2020classification} & -0.09/-0.11 \\\\\n",
      "\\data{cresci-2015} & 0.98/0.98/0.98  & 3 & \\cite{cresci2015fame} & -0.01/-0.01 \\\\\n",
      "\\data{yang-2013} & 0.96/0.71/0.79  & 4 & \\cite{yang2013empirical} & -0.03/-0.19 \\\\\n",
      "\\data{caverlee-2011} & 0.91/0.91/0.90  & 2 & \\cite{lee2011a} & -0.08/-0.07 \\\\\n"
     ]
    }
   ],
   "source": [
    "print_single_dataset_score_table(score_dict, sdt_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
